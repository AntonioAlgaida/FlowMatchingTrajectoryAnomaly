{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eaaf18e",
   "metadata": {},
   "source": [
    "# Deep-Flow: Vector Field Visualization\n",
    "Visualizing the learned probability density in the Latent PCA Manifold.\n",
    "\n",
    "**Axes:**\n",
    "*   **X:** Principal Component 1 (Usually Speed/Distance)\n",
    "*   **Y:** Principal Component 2 (Usually Steering/Curvature)\n",
    "*   **Arrows:** The velocity $v_t$ predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db832936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "if not hasattr(matplotlib.RcParams, '_get'):\n",
    "    matplotlib.RcParams._get = lambda self, key: self.get(key)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from omegaconf import OmegaConf\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path: sys.path.append(project_root)\n",
    "\n",
    "from src.models.deep_flow import DeepFlow\n",
    "from src.dataset.waymo_dataset import WaymoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687a5b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Parallel Eager Load (20 workers)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8856/8856 [00:14<00:00, 601.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… validation split loaded. Count: 8856\n",
      "Scenario: d932c7648c73548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ## 1. Load Model & Data\n",
    "\n",
    "# %%\n",
    "cfg = OmegaConf.load(\"../configs/main_config.yaml\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = DeepFlow(cfg).to(device)\n",
    "checkpoint = torch.load(\"../checkpoints/best_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "\n",
    "# Load stats for reference and PCA basis for visualization\n",
    "with open(\"/mnt/d/waymo_datasets/Deep-Flow_Dataset//stats.json\", \"r\") as f: stats = json.load(f)\n",
    "with open(\"/mnt/d/waymo_datasets/Deep-Flow_Dataset/pca_basis.json\", \"r\") as f: pca_data = json.load(f)\n",
    "\n",
    "# Load a scenario\n",
    "val_set = WaymoDataset(cfg, split='validation', in_memory=True)\n",
    "idx = 15 # Pick a turning scenario if possible\n",
    "batch = val_set[idx]\n",
    "batch_torch = {k: v.unsqueeze(0).to(device) if isinstance(v, torch.Tensor) else v \n",
    "               for k, v in batch.items()}\n",
    "\n",
    "print(f\"Scenario: {batch['scenario_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17e59a",
   "metadata": {},
   "source": [
    "## 2. Compute the 2D Slice of the Vector Field\n",
    "We create a grid of points $(c_1, c_2)$ ranging from -3 to +3 standard deviations.\n",
    "We set components $c_3 \\dots c_{12}$ to 0 (the mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110c0f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_field(model, batch, t_value, grid_size=20):\n",
    "    # 1. Encode Context ONCE\n",
    "    context, goal_emb = model.encoder(\n",
    "        batch['agent_context'], batch['agent_mask'], \n",
    "        batch['map_context'], batch['map_mask'], batch['goal_pos']\n",
    "    )\n",
    "    \n",
    "    # 2. Create Grid\n",
    "    # Range: -4 to +4 (Standard Deviations in PCA space)\n",
    "    x = np.linspace(-10, 10, grid_size)\n",
    "    y = np.linspace(-10, 10, grid_size)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Flatten grid to batch: [N_points, 2]\n",
    "    grid_flat = np.stack([X.flatten(), Y.flatten()], axis=1)\n",
    "    N = grid_flat.shape[0]\n",
    "    \n",
    "    # 3. Construct Input Latent Vectors [N, 12]\n",
    "    # Set C1, C2 from grid. Set C3..C12 to 0.0\n",
    "    latents = torch.zeros(N, 12, device=device)\n",
    "    latents[:, 0] = torch.from_numpy(grid_flat[:, 0])\n",
    "    latents[:, 1] = torch.from_numpy(grid_flat[:, 1])\n",
    "    \n",
    "    # 4. Prepare Time and Context tiles\n",
    "    t = torch.ones(N, device=device) * t_value\n",
    "    ctx_tile = context.repeat(N, 1)\n",
    "    goal_tile = goal_emb.repeat(N, 1)\n",
    "    \n",
    "    # 5. Predict Velocity\n",
    "    with torch.no_grad():\n",
    "        v = model.flow_head(latents, t, ctx_tile, goal_tile)\n",
    "        \n",
    "    # Extract velocity for C1 and C2\n",
    "    U = v[:, 0].view(grid_size, grid_size).cpu().numpy()\n",
    "    V = v[:, 1].view(grid_size, grid_size).cpu().numpy()\n",
    "    \n",
    "    return X, Y, U, V\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232843c",
   "metadata": {},
   "source": [
    "## 3. Interactive Streamline Plot\n",
    "Slide `t` from 0.0 (Noise) to 1.0 (Data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df4b3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde2f13fbad24c55990306d2a062b61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='t', max=1.0), Output()), _dom_classes=('widget-interâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_field(t=0.5):\n",
    "    X, Y, U, V = compute_field(model, batch_torch, t_value=t)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Speed of flow (magnitude)\n",
    "    speed = np.sqrt(U**2 + V**2)\n",
    "    \n",
    "    # Streamplot: Shows the \"paths\" particles would take\n",
    "    strm = ax.streamplot(X, Y, U, V, color=speed, cmap='autumn', linewidth=1.5, density=1.5)\n",
    "    fig.colorbar(strm.lines, label='Flow Magnitude (Correction Strength)')\n",
    "    \n",
    "    # Mark the \"Attractor\" (Where flow goes to 0)\n",
    "    # This roughly corresponds to the model's prediction for this scenario\n",
    "    ax.scatter(0, 0, color='black', marker='+', s=100, label='Mean Trajectory')\n",
    "    \n",
    "    ax.set_title(f\"Learned Vector Field (PC1 vs PC2) @ t={t:.2f}\")\n",
    "    ax.set_xlabel(f\"PC1: Speed/Distance (approx) | Var: {pca_data['explained_variance'][0]*100:.1f}%\")\n",
    "    ax.set_ylabel(f\"PC2: Steering/Curvature (approx) | Var: {pca_data['explained_variance'][1]*100:.1f}%\")\n",
    "    ax.set_xlim(-10, 10)\n",
    "    ax.set_ylim(-10, 10)\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "interact(plot_field, t=FloatSlider(min=0.0, max=1.0, step=0.1, value=0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee8ffa",
   "metadata": {},
   "source": [
    "## 4. Probability Density Contours\n",
    "Instead of arrows, we visualize the **Probability Mass**.\n",
    "We sample 1,000 particles from noise ($x_0$) and push them to time $t$.\n",
    "The resulting density shows the \"Confidence Envelope\" of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718d8e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9a6e22c3704ed38e3e1d75fc4a0714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.9, description='Time (t)', max=1.0, min=0.1), IntSlider(value=2000, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "from ipywidgets import fixed\n",
    "\n",
    "@torch.no_grad()\n",
    "def plot_density_contours(model, batch_torch, t_value, pca_data, n_particles=2000):\n",
    "    # 1. Encode Context\n",
    "    context, goal_emb = model.encoder(\n",
    "        batch_torch['agent_context'], batch_torch['agent_mask'], \n",
    "        batch_torch['map_context'], batch_torch['map_mask'], batch_torch['goal_pos']\n",
    "    )\n",
    "    \n",
    "    # 2. Sample Particles (x0)\n",
    "    # We sample a cloud of points in the 12D latent space\n",
    "    curr_coeffs = torch.randn(n_particles, 12, device=device)\n",
    "    \n",
    "    # 3. Integrate to time t (Euler)\n",
    "    steps = int(t_value * 50) # Scale steps by t\n",
    "    if steps == 0: steps = 1\n",
    "    dt = t_value / steps\n",
    "    \n",
    "    # Expand context\n",
    "    ctx_tile = context.repeat(n_particles, 1)\n",
    "    goal_tile = goal_emb.repeat(n_particles, 1)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        t_tensor = torch.ones(n_particles, device=device) * (i * dt)\n",
    "        v = model.flow_head(curr_coeffs, t_tensor, ctx_tile, goal_tile)\n",
    "        curr_coeffs = curr_coeffs + v * dt\n",
    "        \n",
    "    # 4. Extract PC1 and PC2 for plotting\n",
    "    # shape: [N, 12] -> we want [N, 0] and [N, 1]\n",
    "    data = curr_coeffs.cpu().numpy()\n",
    "    x = data[:, 0]\n",
    "    y = data[:, 1]\n",
    "    \n",
    "    # 5. Plotting\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # A. Plot the Vector Field Background (Subtle)\n",
    "    # Re-use previous compute function for background context\n",
    "    GX, GY, GU, GV = compute_field(model, batch_torch, t_value, grid_size=15)\n",
    "    ax.streamplot(GX, GY, GU, GV, color='gray', linewidth=0.5, density=1.0)\n",
    "    \n",
    "    # B. Plot the Density Contours (KDE)\n",
    "    # This draws the \"Mountain\" of probability\n",
    "    sns.kdeplot(x=x, y=y, fill=True, cmap=\"viridis\", alpha=0.6, levels=10, ax=ax, thresh=0.05)\n",
    "    \n",
    "    # C. Plot the Expert Ground Truth (Red Star)\n",
    "    # We need to project the expert GT into PCA space to see where it falls\n",
    "    gt_action = batch_torch['target_action'].cpu().numpy()[0] # [12]\n",
    "    ax.scatter(gt_action[0], gt_action[1], color='red', s=200, marker='*', label='Expert GT', zorder=10)\n",
    "    \n",
    "    # D. Labels\n",
    "    ax.set_title(f\"Probability Density Manifold @ t={t_value:.2f}\")\n",
    "    ax.set_xlabel(f\"PC1 (Speed) | Expert Value: {gt_action[0]:.2f}\")\n",
    "    ax.set_ylabel(f\"PC2 (Steering) | Expert Value: {gt_action[1]:.2f}\")\n",
    "    ax.set_xlim(-10, 10)\n",
    "    ax.set_ylim(-10, 10)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle=':', alpha=0.5)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Interactive Slider\n",
    "interact(plot_density_contours, \n",
    "         model=fixed(model),           # <--- Use fixed() to pass the model\n",
    "         batch_torch=fixed(batch_torch), # <--- Use fixed() to pass the data\n",
    "         pca_data=fixed(pca_data),       # <--- Use fixed() to pass the PCA dict\n",
    "         t_value=FloatSlider(min=0.1, max=1.0, step=0.1, value=0.9, description=\"Time (t)\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca67245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep-Flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
